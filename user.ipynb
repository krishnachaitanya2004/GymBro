{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "687d6591",
   "metadata": {},
   "source": [
    "## Trainer Code\n",
    "\n",
    "This notebook takes trainer video, which will be ideal for exercise and processing too. \n",
    "Trainer video will directly start the exercise, so initial position will be 0th frame\n",
    "Trainer video contains side view of trainer and isn't tilted\n",
    "Trainer will do one round of exercise only\n",
    "The points and angles obtained will be stored in csv and used to compare with user frames for counting no of correct reps. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7015692a",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9ce72a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gdown\n",
    "\n",
    "pose_model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
    "movenet = pose_model.signatures['serving_default']\n",
    "key_frames_angles = []\n",
    "key_frames_points = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980f7120",
   "metadata": {},
   "source": [
    "## Change the name of input video to whatever the user wants to check on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "502f3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video = \"wrong_pushup.mp4\"\n",
    "exercise_name = \"PushUp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fdd2049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_angle = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007d6ef6",
   "metadata": {},
   "source": [
    "## Change trainer video to desired exercise video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9c10242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer_video = \"pushup.gif\"\n",
    "if not os.path.exists(exercise_name):\n",
    "    os.makedirs(exercise_name)\n",
    "    print(f\"Directory '{exercise_name}' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af39ec42",
   "metadata": {},
   "source": [
    "### Get angles and key points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41ce95ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Returns key points by taking model output on a image\n",
    "def get_keypoints(outputs):\n",
    "    points = outputs['output_0'].numpy()[0, 0, :, :]\n",
    "    nose = points[0]\n",
    "    left_shoulder = points[5]\n",
    "    right_shoulder = points[6]\n",
    "    left_elbow = points[7]\n",
    "    right_elbow = points[8]\n",
    "    left_wrist = points[9]\n",
    "    right_wrist = points[10]\n",
    "    left_hip = points[11]\n",
    "    right_hip = points[12]\n",
    "    left_knee = points[13]\n",
    "    right_knee = points[14]\n",
    "    left_ankle = points[15]\n",
    "    right_ankle = points[16]\n",
    "    neck = (left_shoulder + right_shoulder) / 2\n",
    "\n",
    "    body_parts = {\n",
    "        'nose': nose,\n",
    "        'left_shoulder': left_shoulder,\n",
    "        'right_shoulder': right_shoulder,\n",
    "        'left_elbow': left_elbow,\n",
    "        'right_elbow': right_elbow,\n",
    "        'left_wrist': left_wrist,\n",
    "        'right_wrist': right_wrist,\n",
    "        'left_hip': left_hip,\n",
    "        'right_hip': right_hip,\n",
    "        'left_knee': left_knee,\n",
    "        'right_knee': right_knee,\n",
    "        'left_ankle': left_ankle,\n",
    "        'right_ankle': right_ankle,\n",
    "        'neck': neck\n",
    "    }\n",
    "    return body_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "915b7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_angle(v1, v2):\n",
    "    numer = np.dot(v1, v2)\n",
    "    denom = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "    if denom == 0:\n",
    "        if np.array_equal(v1, v2):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return 180.0\n",
    "    degrees = np.degrees(np.arccos(numer / denom))\n",
    "    return degrees\n",
    "\n",
    "def calculate_angle(point1,point2,point3):\n",
    "    v1 = point1[:2] - point2[:2]\n",
    "    v2 = point3[:2] - point2[:2]\n",
    "    return cosine_angle(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8baba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get angles from key points. \n",
    "def get_angles(keypoints):\n",
    "    n_n_rs = calculate_angle(keypoints['nose'], keypoints['neck'], keypoints['right_elbow'])\n",
    "    n_n_ls = calculate_angle(keypoints['nose'], keypoints['neck'], keypoints['left_elbow'])\n",
    "    n_rs_re = calculate_angle(keypoints['neck'], keypoints['right_shoulder'], keypoints['right_elbow'])\n",
    "    n_ls_le = calculate_angle(keypoints['neck'], keypoints['left_shoulder'], keypoints['left_elbow'])\n",
    "    rs_re_rw = calculate_angle(keypoints['right_shoulder'], keypoints['right_elbow'], keypoints['right_wrist'])\n",
    "    ls_le_lw = calculate_angle(keypoints['left_shoulder'], keypoints['left_elbow'], keypoints['left_wrist'])\n",
    "    n_rh_rk = calculate_angle(keypoints['neck'], keypoints['right_hip'], keypoints['right_knee'])\n",
    "    n_lh_lk = calculate_angle(keypoints['neck'], keypoints['left_hip'], keypoints['left_knee'])\n",
    "    rh_rk_ra = calculate_angle(keypoints['right_hip'], keypoints['right_knee'], keypoints['right_ankle'])\n",
    "    lh_lk_la = calculate_angle(keypoints['left_hip'], keypoints['left_knee'], keypoints['left_ankle'])\n",
    "\n",
    "    angles = {\n",
    "        \"Nose-Neck-Right Shoulder\": n_n_rs,\n",
    "        \"Nose-Neck-Left Shoulder\": n_n_ls,\n",
    "        \"Neck-Right Shoulder-Right Elbow\": n_rs_re,\n",
    "        \"Neck-Left Shoulder-Left Elbow\": n_ls_le,\n",
    "        \"Right Shoulder-Right Elbow-Right Wrist\": rs_re_rw,\n",
    "        \"Left Shoulder-Left Elbow-Left Wrist\": ls_le_lw,\n",
    "        \"Neck-Right Hip-Right Knee\": n_rh_rk,\n",
    "        \"Neck-Left Hip-Left Knee\": n_lh_lk,\n",
    "        \"Right Hip-Right Knee-Right Ankle\": rh_rk_ra,\n",
    "        \"Left Hip-Left Knee-Left Ankle\": lh_lk_la\n",
    "    }\n",
    "\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1db79a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes input as image path and return all angles and points\n",
    "def get_data_from_model(image):\n",
    "\n",
    "    image_tensor = tf.image.resize_with_pad(image, 192, 192)\n",
    "    image_tensor = tf.cast(image_tensor, dtype=tf.int32)\n",
    "    image_tensor = tf.expand_dims(image_tensor, axis=0)\n",
    "\n",
    "    # Run the model.\n",
    "    outputs = movenet(image_tensor)\n",
    "    keypoints = get_keypoints(outputs)\n",
    "    angles = get_angles(keypoints)\n",
    "    return keypoints, angles\n",
    "\n",
    "# Gets angles of current frame and compares wrt prev frame and saves if there is significant difference\n",
    "def process_frame(frame, count, angles):\n",
    "    \n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image = tf.convert_to_tensor(image,dtype=tf.int32)\n",
    "    keypoints, angles1 = get_data_from_model(image)  # Pass the image to the model\n",
    "    angle_diff = sum(abs(angles[key] - angles1[key]) for key in angles)\n",
    "    if angle_diff > threshold_angle:\n",
    "        filename = f\"pose{count}.jpg\"\n",
    "        filename = os.path.join(exercise_name,filename)\n",
    "        cv2.imwrite(filename, frame)\n",
    "        angles = angles1\n",
    "        key_frames_angles.append(angles)\n",
    "        key_frames_points.append(keypoints)\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f164369",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(trainer_video)\n",
    "count = 0\n",
    "ret, frame = video.read()\n",
    "\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "else:\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image = tf.convert_to_tensor(image,dtype=tf.int32)\n",
    "\n",
    "    _, angles = get_data_from_model(image)\n",
    "    count += 1\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        angles = process_frame(frame, count, angles)\n",
    "        \n",
    "        count += 1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4993944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_file1 = \"key_frame_angles.csv\"\n",
    "csv_file2 = \"key_frame_points.csv\"\n",
    "csv_file1 = os.path.join(exercise_name,csv_file1)\n",
    "csv_file2 = os.path.join(exercise_name,csv_file2)\n",
    "# Extract the headers from the first dictionary (keys of the dictionary)\n",
    "headers1 = key_frames_angles[0].keys()\n",
    "headers2 = key_frames_points[0].keys()\n",
    "\n",
    "# Write data to CSV\n",
    "with open(csv_file1, \"w\", newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=headers1)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(key_frames_angles)\n",
    "# Write data to CSV\n",
    "with open(csv_file2, \"w\", newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=headers2)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(key_frames_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4914f25b",
   "metadata": {},
   "source": [
    "# User Code \n",
    "\n",
    "This notebook takes user video , processes the key frames to compare them to the trainer frames stored in csv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6c3177",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17d16227-931c-4436-adde-2ffca0348577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "pose_model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
    "movenet = pose_model.signatures['serving_default']\n",
    "\n",
    "key_frames_angles = []\n",
    "key_frames_points = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab08fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map of indices and body parts\n",
    "body_parts = {\n",
    "    0: \"Nose-Neck-Right Shoulder\",\n",
    "    1: \"Nose-Neck-Left Shoulder\",\n",
    "    2: \"Neck-Right Shoulder-Right Elbow\",\n",
    "    3: \"Neck-Left Shoulder-Left Elbow\",\n",
    "    4: \"Right Shoulder-Right Elbow-Right Wrist\",\n",
    "    5: \"Left Shoulder-Left Elbow-Left Wrist\",\n",
    "    6: \"Neck-Right Hip-Right Knee\",\n",
    "    7: \"Neck-Left Hip-Left Knee\",\n",
    "    8: \"Right Hip-Right Knee-Right Ankle\",\n",
    "    9: \"Left Hip-Left Knee-Left Ankle\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b2d4a0d-e6db-4a8f-88bc-feb5778878e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = os.path.join(exercise_name,\"key_frame_angles.csv\")\n",
    "\n",
    "with open(csv_file, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    data = [dict(row) for row in reader]\n",
    "\n",
    "csv_file = os.path.join(exercise_name,\"key_frame_points.csv\")\n",
    "\n",
    "with open(csv_file, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    data2 = [dict(row) for row in reader]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c1f2618-f2a8-4126-b252-32b4e3045ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_frames_angles = [[float(d[key]) for key in d] for d in data]\n",
    "key_frames_points = [[d[key] for key in d] for d in data2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d903b3ff-ab68-4000-8260-12ff07562713",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_frames_points = [[[float(co) for co in part.strip(\"[]\").split() ] for part in frame] for frame in key_frames_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d82ccc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_frame_count = len(key_frames_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2bdc9e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Returns key points by taking model output on a image\n",
    "def get_keypoints(outputs):\n",
    "    points = outputs['output_0'].numpy()[0, 0, :, :]\n",
    "    nose = points[0]\n",
    "    left_shoulder = points[5]\n",
    "    right_shoulder = points[6]\n",
    "    left_elbow = points[7]\n",
    "    right_elbow = points[8]\n",
    "    left_wrist = points[9]\n",
    "    right_wrist = points[10]\n",
    "    left_hip = points[11]\n",
    "    right_hip = points[12]\n",
    "    left_knee = points[13]\n",
    "    right_knee = points[14]\n",
    "    left_ankle = points[15]\n",
    "    right_ankle = points[16]\n",
    "    neck = (left_shoulder + right_shoulder) / 2\n",
    "\n",
    "    body_parts = {\n",
    "        'nose': nose,\n",
    "        'left_shoulder': left_shoulder,\n",
    "        'right_shoulder': right_shoulder,\n",
    "        'left_elbow': left_elbow,\n",
    "        'right_elbow': right_elbow,\n",
    "        'left_wrist': left_wrist,\n",
    "        'right_wrist': right_wrist,\n",
    "        'left_hip': left_hip,\n",
    "        'right_hip': right_hip,\n",
    "        'left_knee': left_knee,\n",
    "        'right_knee': right_knee,\n",
    "        'left_ankle': left_ankle,\n",
    "        'right_ankle': right_ankle,\n",
    "        'neck': neck\n",
    "    }\n",
    "    return body_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aeaa5b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_angle(v1, v2):\n",
    "    numer = np.dot(v1, v2)\n",
    "    denom = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "    if denom == 0:\n",
    "        if np.array_equal(v1, v2):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return 180.0\n",
    "    degrees = np.degrees(np.arccos(numer / denom))\n",
    "    return degrees\n",
    "\n",
    "def calculate_angle(point1,point2,point3):\n",
    "    v1 = point1[:2] - point2[:2]\n",
    "    v2 = point3[:2] - point2[:2]\n",
    "    return cosine_angle(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6b9bb2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get angles from key points. \n",
    "def get_angles(keypoints):\n",
    "    n_n_rs = calculate_angle(keypoints['nose'], keypoints['neck'], keypoints['right_elbow'])\n",
    "    n_n_ls = calculate_angle(keypoints['nose'], keypoints['neck'], keypoints['left_elbow'])\n",
    "    n_rs_re = calculate_angle(keypoints['neck'], keypoints['right_shoulder'], keypoints['right_elbow'])\n",
    "    n_ls_le = calculate_angle(keypoints['neck'], keypoints['left_shoulder'], keypoints['left_elbow'])\n",
    "    rs_re_rw = calculate_angle(keypoints['right_shoulder'], keypoints['right_elbow'], keypoints['right_wrist'])\n",
    "    ls_le_lw = calculate_angle(keypoints['left_shoulder'], keypoints['left_elbow'], keypoints['left_wrist'])\n",
    "    n_rh_rk = calculate_angle(keypoints['neck'], keypoints['right_hip'], keypoints['right_knee'])\n",
    "    n_lh_lk = calculate_angle(keypoints['neck'], keypoints['left_hip'], keypoints['left_knee'])\n",
    "    rh_rk_ra = calculate_angle(keypoints['right_hip'], keypoints['right_knee'], keypoints['right_ankle'])\n",
    "    lh_lk_la = calculate_angle(keypoints['left_hip'], keypoints['left_knee'], keypoints['left_ankle'])\n",
    "\n",
    "    angles = {\n",
    "        \"Nose-Neck-Right Shoulder\": n_n_rs,\n",
    "        \"Nose-Neck-Left Shoulder\": n_n_ls,\n",
    "        \"Neck-Right Shoulder-Right Elbow\": n_rs_re,\n",
    "        \"Neck-Left Shoulder-Left Elbow\": n_ls_le,\n",
    "        \"Right Shoulder-Right Elbow-Right Wrist\": rs_re_rw,\n",
    "        \"Left Shoulder-Left Elbow-Left Wrist\": ls_le_lw,\n",
    "        \"Neck-Right Hip-Right Knee\": n_rh_rk,\n",
    "        \"Neck-Left Hip-Left Knee\": n_lh_lk,\n",
    "        \"Right Hip-Right Knee-Right Ankle\": rh_rk_ra,\n",
    "        \"Left Hip-Left Knee-Left Ankle\": lh_lk_la\n",
    "    }\n",
    "\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd500dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(image):\n",
    "    image_tensor = tf.image.resize_with_pad(image, 192, 192)\n",
    "    image_tensor = tf.cast(image_tensor, dtype=tf.int32)\n",
    "    image_tensor = tf.expand_dims(image_tensor, axis=0)\n",
    "    \n",
    "    # Run the model.\n",
    "    outputs = movenet(image_tensor)\n",
    "    keypoints = outputs['output_0'].numpy()[0, 0, :, :]\n",
    "    \n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "77b22a4c-a5d3-41d9-a567-b57eebad337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def l1_norm(l1, l2):\n",
    "    if len(l1) != len(l2):\n",
    "        raise ValueError(\"Lists must be of the same length.\")\n",
    "    err = np.sum(np.abs(np.array(l1) - np.array(l2)))\n",
    "    ind = np.argmax(err)\n",
    "    return err, ind\n",
    "\n",
    "def get_angles_from_model(frame):\n",
    "    # Convert the frame from BGR to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert the frame to a TensorFlow tensor\n",
    "    image = tf.convert_to_tensor(frame_rgb, dtype=tf.int32)\n",
    "    \n",
    "    image_tensor = tf.image.resize_with_pad(image, 192, 192)\n",
    "    image_tensor = tf.cast(image_tensor, dtype=tf.int32)\n",
    "    image_tensor = tf.expand_dims(image_tensor, axis=0)\n",
    "\n",
    "    # Run the model.\n",
    "    outputs = movenet(image_tensor)\n",
    "    keypoints = get_keypoints(outputs)\n",
    "    angles = get_angles(keypoints)\n",
    "    return angles,keypoints\n",
    "\n",
    "  \n",
    "def process_frame(frame, frame_id_from_trainer,mapping_frames):\n",
    "    angles1,keypoints = get_angles_from_model(frame)\n",
    "    angles_only = [float(angles1[key]) for key in angles1]\n",
    "    # closest_frame = None\n",
    "    prob = ''\n",
    "    if(frame_id_from_trainer == len(key_frames_angles)):\n",
    "        return 0\n",
    "    d_cur, ind_cur = l1_norm(key_frames_angles[frame_id_from_trainer], angles_only)\n",
    "    d_next, ind_next = l1_norm(key_frames_angles[(frame_id_from_trainer+1)%trainer_frame_count], angles_only)\n",
    "    if d_next<d_cur:\n",
    "        frame_id_from_trainer=  (frame_id_from_trainer+1)%trainer_frame_count\n",
    "        prob = 'Problem in ' + body_parts[ind_next] + ' Angle'\n",
    "    else:\n",
    "        prob = 'Problem in ' + body_parts[ind_cur] + ' Angle'\n",
    "\n",
    "    mapping_frames.append({'user':keypoints,'trainer':key_frames_points[frame_id_from_trainer], 'problem': prob})\n",
    "    return frame_id_from_trainer\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "00d4c8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a67bb817-db72-496c-82eb-d94673d81cfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "0 8\n",
      "0 9\n",
      "0 10\n",
      "0 11\n",
      "0 12\n",
      "0 13\n",
      "0 14\n",
      "0 15\n",
      "0 16\n",
      "0 17\n",
      "0 18\n",
      "0 19\n",
      "0 20\n",
      "0 21\n",
      "0 22\n",
      "0 23\n",
      "0 24\n",
      "0 25\n",
      "0 26\n",
      "0 27\n",
      "0 28\n",
      "0 29\n",
      "0 30\n",
      "0 31\n",
      "0 32\n",
      "0 33\n",
      "0 34\n",
      "0 35\n",
      "0 36\n",
      "0 37\n",
      "0 38\n",
      "0 39\n",
      "0 40\n",
      "0 41\n",
      "1 42\n",
      "2 43\n",
      "3 44\n",
      "4 45\n",
      "5 46\n",
      "6 47\n",
      "7 48\n",
      "8 49\n",
      "9 50\n",
      "9 51\n",
      "9 52\n",
      "9 53\n",
      "9 54\n",
      "9 55\n",
      "9 56\n",
      "9 57\n",
      "9 58\n",
      "10 59\n",
      "10 60\n",
      "10 61\n",
      "11 62\n",
      "11 63\n",
      "11 64\n",
      "11 65\n",
      "12 66\n",
      "12 67\n",
      "12 68\n",
      "12 69\n",
      "12 70\n",
      "12 71\n",
      "12 72\n",
      "12 73\n",
      "12 74\n",
      "12 75\n",
      "12 76\n",
      "12 77\n",
      "12 78\n",
      "12 79\n",
      "12 80\n",
      "12 81\n",
      "12 82\n",
      "12 83\n",
      "12 84\n",
      "12 85\n",
      "12 86\n",
      "12 87\n",
      "12 88\n",
      "12 89\n",
      "12 90\n",
      "12 91\n",
      "12 92\n",
      "12 93\n",
      "12 94\n",
      "12 95\n",
      "12 96\n",
      "13 97\n",
      "14 98\n",
      "15 99\n",
      "16 100\n",
      "17 101\n",
      "17 102\n",
      "17 103\n",
      "17 104\n",
      "17 105\n",
      "17 106\n",
      "17 107\n",
      "17 108\n",
      "17 109\n",
      "17 110\n",
      "17 111\n",
      "17 112\n",
      "17 113\n",
      "17 114\n",
      "17 115\n",
      "17 116\n",
      "17 117\n",
      "17 118\n",
      "17 119\n",
      "17 120\n",
      "17 121\n",
      "17 122\n",
      "17 123\n",
      "17 124\n",
      "17 125\n",
      "17 126\n",
      "17 127\n",
      "17 128\n",
      "17 129\n",
      "17 130\n",
      "17 131\n",
      "17 132\n",
      "17 133\n",
      "17 134\n",
      "17 135\n",
      "17 136\n",
      "17 137\n",
      "17 138\n",
      "17 139\n",
      "17 140\n",
      "17 141\n",
      "17 142\n",
      "17 143\n",
      "17 144\n",
      "17 145\n",
      "17 146\n",
      "17 147\n",
      "17 148\n",
      "17 149\n",
      "17 150\n",
      "17 151\n",
      "17 152\n",
      "17 153\n",
      "17 154\n",
      "17 155\n",
      "17 156\n",
      "17 157\n",
      "17 158\n",
      "17 159\n",
      "17 160\n",
      "17 161\n",
      "17 162\n",
      "17 163\n",
      "17 164\n",
      "17 165\n",
      "17 166\n",
      "17 167\n",
      "17 168\n",
      "17 169\n",
      "17 170\n",
      "17 171\n",
      "17 172\n",
      "17 173\n",
      "17 174\n",
      "17 175\n",
      "17 176\n",
      "17 177\n",
      "17 178\n",
      "17 179\n",
      "17 180\n",
      "17 181\n",
      "17 182\n",
      "0 183\n",
      "0 184\n",
      "0 185\n",
      "1 186\n",
      "2 187\n",
      "3 188\n",
      "4 189\n",
      "5 190\n",
      "6 191\n",
      "7 192\n",
      "8 193\n",
      "9 194\n",
      "9 195\n",
      "9 196\n",
      "9 197\n",
      "9 198\n",
      "9 199\n",
      "9 200\n",
      "10 201\n",
      "10 202\n",
      "10 203\n",
      "11 204\n",
      "11 205\n",
      "11 206\n",
      "11 207\n",
      "11 208\n",
      "11 209\n",
      "12 210\n",
      "12 211\n",
      "12 212\n",
      "12 213\n",
      "12 214\n",
      "12 215\n",
      "12 216\n",
      "12 217\n",
      "12 218\n",
      "12 219\n",
      "12 220\n",
      "12 221\n",
      "12 222\n",
      "13 223\n",
      "14 224\n",
      "15 225\n",
      "15 226\n",
      "15 227\n",
      "16 228\n",
      "17 229\n",
      "17 230\n",
      "17 231\n",
      "17 232\n",
      "17 233\n",
      "17 234\n",
      "17 235\n",
      "17 236\n",
      "17 237\n",
      "17 238\n",
      "17 239\n",
      "17 240\n",
      "17 241\n",
      "0 242\n",
      "0 243\n",
      "0 244\n",
      "0 245\n",
      "0 246\n",
      "0 247\n",
      "0 248\n",
      "0 249\n",
      "0 250\n",
      "0 251\n",
      "0 252\n",
      "0 253\n",
      "0 254\n",
      "0 255\n",
      "0 256\n",
      "0 257\n",
      "0 258\n",
      "0 259\n",
      "0 260\n",
      "0 261\n",
      "0 262\n",
      "0 263\n",
      "0 264\n",
      "0 265\n",
      "0 266\n",
      "0 267\n",
      "0 268\n",
      "0 269\n",
      "0 270\n",
      "0 271\n",
      "0 272\n",
      "0 273\n",
      "0 274\n",
      "0 275\n",
      "0 276\n",
      "0 277\n",
      "0 278\n",
      "0 279\n",
      "0 280\n",
      "0 281\n",
      "0 282\n",
      "0 283\n",
      "0 284\n",
      "0 285\n",
      "0 286\n",
      "0 287\n",
      "0 288\n",
      "0 289\n"
     ]
    }
   ],
   "source": [
    "mapping_frames = []\n",
    "final_frames = []\n",
    "def main():\n",
    "    video = cv2.VideoCapture(\"wrong_pushup.mp4\")\n",
    "    count = 0\n",
    "    wait_count = 0\n",
    "    frame_id = 0\n",
    "    num_frames = 0\n",
    "    old_frame_index = 0\n",
    "    old_frame = 0\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Skip 4 out of 5 frames\n",
    "        frame_id = process_frame(frame, frame_id,mapping_frames)\n",
    "        if(old_frame!= frame_id):\n",
    "            final_frames.append([old_frame_index,num_frames-1])\n",
    "            old_frame_index = num_frames\n",
    "            \n",
    "\n",
    "        old_frame = frame_id\n",
    "        print(frame_id,num_frames)\n",
    "        \n",
    "\n",
    "        if (frame_id == 0):\n",
    "            count += 1\n",
    "        num_frames += 1\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    final_frames.append([old_frame_index,num_frames-1])\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b64e621b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapping_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "921a9419-d6bd-49e6-8806-a662e641c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([d['trainer'] for d in mapping_frames])\n",
    "Y = np.array([d['user'] for d in mapping_frames])\n",
    "Y = np.array([[frame[key] for key in frame] for frame in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5db9027b-8ac7-4994-829e-ebea8920d275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290, 14, 3)\n",
      "(290, 14, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a0c1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_Y = []\n",
    "\n",
    "for left, right in final_frames:\n",
    "        frame_left = Y[left]\n",
    "        frame_right = Y[right]\n",
    "        # print(left)\n",
    "        a = right-left+1\n",
    "        # print(right)\n",
    "        # print(a)\n",
    "        if(a==1):\n",
    "            final_Y.append(frame_left)\n",
    "            continue\n",
    "        for i in range(a):\n",
    "            # print(a-i)\n",
    "            final_Y.append(((a-i-1)*frame_left + i*frame_right)/(a-1))\n",
    "        # print(right,len(final_Y),a)\n",
    "Y = np.array(final_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eab4c73d-d0ae-4f43-8c16-c3618436b630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46218392, 0.8383655 , 0.55697393])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "229c8fe4-ec91-4d3a-9def-8da9e452369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_to_2d(frame):\n",
    "    sliced_matrix = frame[:, :, :2]  # This will have the shape (40, 14, 2)\n",
    "    reshaped_matrix = sliced_matrix.reshape(-1, 2)  # Reshape to (40*14, 2)\n",
    "    return reshaped_matrix\n",
    "X1 = convert_to_2d(X)\n",
    "Y1 = convert_to_2d(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ff7f9e44-1fa4-4a0c-a162-138253d672b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized A:\n",
      "[[ 0.57771126 -0.04797943]\n",
      " [-0.04076296  0.92072509]]\n",
      "Optimized b:\n",
      "[ 0.17769757 -0.02764757]\n"
     ]
    }
   ],
   "source": [
    "# We will show positions to user based on trainer video. For that affine transformation from trainer to user should be done\n",
    "import numpy as np\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "def affine_transformation(X, Y):\n",
    "    n, m = X.shape\n",
    "\n",
    "    def residuals(params):\n",
    "        A = params[:m*m].reshape(m, m)\n",
    "        b = params[m*m:]\n",
    "        return (Y - (X @ A + b)).flatten()\n",
    "\n",
    "    initial_guess = np.zeros((m * m) + m)\n",
    "    result = least_squares(residuals, initial_guess)\n",
    "    optimized_params = result.x\n",
    "    A_opt = optimized_params[:m*m].reshape(m, m)\n",
    "    b_opt = optimized_params[m*m:]\n",
    "    \n",
    "    return A_opt, b_opt\n",
    "\n",
    "A_opt, b_opt = affine_transformation(X1, Y1)\n",
    "\n",
    "print(\"Optimized A:\")\n",
    "print(A_opt)\n",
    "print(\"Optimized b:\")\n",
    "print(b_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "525d2415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines_user(keypoints,frame,width,height):\n",
    "    connections = [\n",
    "        (0, 1), (1, 2), (2, 3), (0, 4), (4, 5), (5, 6),  # Head\n",
    "        (6, 8), (8, 10), (5, 7), (7, 9),  # Arms\n",
    "        (6, 12), (12, 14), (14, 16), (5, 11), (11, 13), (13, 15),  # Legs\n",
    "        (11, 12)  \n",
    "    ]\n",
    "\n",
    "    for pt in connections:\n",
    "        x,y = pt\n",
    "        if(keypoints[x][2] > 0.3 and keypoints[y][2] > 0.3):\n",
    "            x_a = int(keypoints[x][1]*width)\n",
    "            y_a = int(keypoints[x][0]*height)\n",
    "            x_b = int(keypoints[y][1]*width)\n",
    "            y_b = int(keypoints[y][0]*height)\n",
    "            cv2.line(frame, (x_a, y_a), (x_b, y_b), (0, 0, 255), 2)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e8922882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines_trainer(points, frame,width,height):\n",
    "    connections = [\n",
    "        (0, 1), (1,2), (1,3), (2,4), (4,6) , (3,5), (5,7), (1,8), (1,9), (8,10), (9,11), (10,12), (11,13)\n",
    "    ]\n",
    "\n",
    "    for pt in connections:\n",
    "        x,y = pt\n",
    "        x_a = int(points[x][1])\n",
    "        y_a = int(points[x][0])\n",
    "        x_b = int(points[y][1])\n",
    "        y_b = int(points[y][0])\n",
    "        cv2.line(frame, (x_a, y_a), (x_b, y_b), (0, 255, 0), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f70d973c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.46218392 0.8383655  0.55697393]\n",
      " [0.4362504  0.70156425 0.73102593]\n",
      " [0.44442138 0.7325984  0.79765177]\n",
      " [0.56914806 0.65825725 0.6244836 ]\n",
      " [0.58961695 0.67819065 0.58298576]\n",
      " [0.6766716  0.66571444 0.6589131 ]\n",
      " [0.7245861  0.7045313  0.8648901 ]\n",
      " [0.48684645 0.48715037 0.7160776 ]\n",
      " [0.49075055 0.48461437 0.6765288 ]\n",
      " [0.5681819  0.29134303 0.5311298 ]\n",
      " [0.5722823  0.29169473 0.850004  ]\n",
      " [0.61683524 0.10930017 0.7851962 ]\n",
      " [0.62781    0.08928271 0.76107085]\n",
      " [0.44033587 0.7170813  0.76433885]]\n",
      "[[0.46218392 0.8383655  0.55697393]\n",
      " [0.4362504  0.70156425 0.73102593]\n",
      " [0.44442138 0.7325984  0.79765177]\n",
      " [0.56914806 0.65825725 0.6244836 ]\n",
      " [0.58961695 0.67819065 0.58298576]\n",
      " [0.6766716  0.66571444 0.6589131 ]\n",
      " [0.7245861  0.7045313  0.8648901 ]\n",
      " [0.48684645 0.48715037 0.7160776 ]\n",
      " [0.49075055 0.48461437 0.6765288 ]\n",
      " [0.5681819  0.29134303 0.5311298 ]\n",
      " [0.5722823  0.29169473 0.850004  ]\n",
      " [0.61683524 0.10930017 0.7851962 ]\n",
      " [0.62781    0.08928271 0.76107085]\n",
      " [0.44033587 0.7170813  0.76433885]]\n"
     ]
    }
   ],
   "source": [
    "print(X[10])\n",
    "print(X[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d998f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "video2 = cv2.VideoCapture(input_video)\n",
    "index = 0\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4\n",
    "out = cv2.VideoWriter('output_pushup.mp4', fourcc, 30.0, (int(video2.get(3)), int(video2.get(4))))\n",
    "while True:\n",
    "    ret, frame = video2.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.int32)\n",
    "    \n",
    "    keypoints = get_data(image)\n",
    "    height, width, _ = frame.shape\n",
    "    points = []\n",
    "    for keypoint in X[index]:\n",
    "        y, x, confidence = keypoint\n",
    "        # if confidence > 0.3:\n",
    "        y_new, x_new = np.matmul(np.array([y, x]), A_opt) + b_opt\n",
    "        x_new = int(x_new * width)\n",
    "        y_new = int(y_new * height)\n",
    "        cv2.circle(frame, (x_new, y_new), 5, (0, 255, 0), -1)\n",
    "        points.append([y_new, x_new])\n",
    "    points = np.array(points)\n",
    "    draw_lines_user(keypoints,frame,width,height)\n",
    "    draw_lines_trainer(points,frame,width,height)\n",
    "    cv2.putText(frame, mapping_frames[index]['problem'], (50, 50), cv2.FONT_HERSHEY_SIMPLEX,0.7, (0, 0, 0), 2,)\n",
    "    index += 1\n",
    "    out.write(frame)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video2.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
